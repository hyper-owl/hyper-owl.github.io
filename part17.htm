<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>7. 참고문헌</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part16.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a></p><h1 style="padding-left: 5pt;text-indent: 0pt;text-align: left;">7. 참고문헌</h1><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 129%;text-align: left;">[1] Coarse-to-Fine Query Focused Multi-Document Summarization (Xu &amp; Lapata, EMNLP 2020)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[2] Manifold-ranking based topic-focused multi-document summarization (Wan &amp; Yang, IJCAI 2007)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;text-align: left;">[3] Weakly Supervised Domain Detection (Xu &amp; Lapata, TACL 2019)</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 129%;text-align: left;">[4] PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization (Zhong et al, ICML 2020)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[5] Text Summarization with Pretrained Encoders (Liu &amp; Lapata, EMNLP 2019)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[6] 사전학습 기반의 법률문서 요약 방법 비교연구 (김의순 &amp; 임희석, ACK 2021)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;text-align: left;">[7] KoBART를 활용한 한국어 혐오 발언 분류 (이상민 &amp; 정영섭, KIISE 2021)</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[8] 검증 자료를 활용한 가짜뉴스 탐지 자동화 연구 (한윤진 &amp; 김근형, KTSDE 2021)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[9] What Have We Achieved on Text Summarization? (Huang &amp; Cui et al, EMNLP 2020)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: left;">[10] A Survey on Neural Network-Based Summarization Methods (Yue Dong, ARXIV 2018)</p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 128%;text-align: justify;">[11] BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (Lewis et al., ACL 2020)</p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;text-align: left;">[12] Abstractive Sentence Summarization with Attentive Recurrent Neural</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Networks (Chopra et al., NAACL 2016)</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: left;">[13]  Yumo  Xu,  Charles,  querysum,  (2020),  GitHub  repository, <span class="s19">https://github.com/yumoxu/querysum#readme</span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: left;">[14] WikiLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization (Ladhak &amp; Durmus, EMNLP 2020)</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part16.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
