<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>3.2 평가 진행</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part8.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a><span> | </span><a href="part10.htm">다음 &gt;</a></p><h2 style="padding-left: 5pt;text-indent: 0pt;text-align: left;">3.2 평가 진행</h2><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">원 논문에서 coarse-to-fine 접근법으로 만든 모델을 querysum으로 부르기 때문 에 편의상, 제가 만든 모델을 KoQuerysum이라고 하겠다. AIHub에서 제공하는 “문서 요약 텍스트”, “요약문 및 레포트 생성데이터“ 등의 데이터를 가지고 3가지 의 모델 KoBART, KoBertSum, KoQuerysum의 성능을 비교할 것이다. 먼저 데이 터에 대하여 train, valid, test 데이터로 분류하고 KoBART와 KoBertSum에 대해 trine 데이터를 가지고 fine-tuning을 진행할 것입니다. 각 모델에 대한 성능 평가 방법으로  문서  요약  테스크에서  흔히  사용하는  ROUGE(Recall-Oriented Understudy for Gisting Evaluation)를 사용한다. ROUGE는 텍스트 자동 요약, 기 계 번역 등 자연어 생성 모델의 성능을 평가하기 위한 지표이며, 모델이 생성한 요 약본 혹은 번역본을 사람이 미리 만들어 놓은 참조본과 대조해 성능 점수를 계산하 는 방법을 사용한다. 본 졸업작품에서는 AI HUB에 공개된 데이터의 original text 와 reference text 를 활용하여 각 모델에서 생성된 text와의 ROUGE F-1score 를 바탕으로 비교 실험을 진행할 것이다.</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part8.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a><span> | </span><a href="part10.htm">다음 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
