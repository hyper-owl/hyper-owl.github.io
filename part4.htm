<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>1. 서 론</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part3.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a><span> | </span><a href="part5.htm">다음 &gt;</a></p><h1 style="padding-left: 16pt;text-indent: 0pt;text-align: left;">1. 서 론</h1><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 128%;text-align: justify;">우리는 인터넷과 모바일 디바이스의 보급으로 인해 다양한 정보를 쉽게 접근할 수 있는 세상에 살고 있다. 하지만, 인터넷에는 수많은 정보가 존재하기 때문에 우리는 원하는 정보를 찾기 위해 다양한 검색 엔진을 사용하고, 이를 통해 다수의 문서를 찾아낸다. 그러나, 이렇게 찾아낸 많은 문서를 모두 읽고 필요로 하는 정보를 찾아 내는 것은 매우 시간과 노력이 들기 때문에, 많은 사용자들은 자신이 원하는 정보 를 찾아내기 위해 많은 시간과 노력을 들이게 된다. 이러한 문제를 해결하기 위해, 문서 요약 기술이 개발되어왔다.</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">최근 다양한 분야에서 사용되고 있는 문서 요약 기술은 정보 검색 및 정보 처리 분 야에서 큰 관심을 받고 있다. 특히 쿼리 중심의 문서 요약 기술은 검색 결과의 효 율성과  정확성을  높이는  데  큰  역할을  한다.  이  중  Query  Focused Multi-Document Summarization (QF-MDS)는 여러 개의 문서에서 주어진 질의 (Query)에 대한 요약(Summarization)을 생성하는 자연어처리(NLP) 태스크이다. 기 존의 단일 문서 요약(Single-Document Summarization)과는 달리, QF-MDS는 여 러 문서에서 정보를 수집하고, 주어진 질의에 대한 정보를 집중적으로 추출하여 요 약을 생성한다. 이를 위해 QF-MDS 시스템은 먼저 주어진 질의를 이해하고, 해당 주제와 관련된 문서를 수집한다. 그리고 각 문서를 분석하여 주요 정보를 추출하고, 주어진 질의와 관련된 내용을 찾아낸다. 마지막으로, 추출된 정보를 결합하여 요약 문을 생성한다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">기존의 쿼리 중심의 문서 요약 모델(QF-MDS)의 경우, text segment들의 연관성 을 분석하여 가장 핵심이라고 생각되는 text segment를 찾은 다음 그 안에서 쿼리 와의 연관성이 높은 부분을 찾아내는 방식이었다. 이러한 방식이 가지고 있는 근본 적인 문제점은 문서에서 핵심적인 문장들을 찾아내는 작업이 쿼리와의 연관성을 고 려하는 작업보다 먼저 일어나기 때문에 문서에 쿼리에 대한 정답이 존재해도 쿼리 의 정답과 문서에서 핵심적으로 다뤄지는 내용 사이에 차이가 있다면 정확도가 낮 아지는 문제가 있었다. 즉, 쿼리에 대한 답을 찾는 과정이 문서의 중심적인 내용을 찾는 과정에 종속 되어있는 문제가 있었다. 반면에 coarse-to-fine modeling framework에서는 문서와 쿼리에 대한 유사도를 판정하는 relevance estimator가 먼저 전체 문서 중 쿼리와 관련이 있는 부분을 추리고, 그 다음 evidence estimator가 요약된 문서에서 쿼리에 대한 답을 찾아낸다. 이후 이렇게 찾아진 답 에서 centrality estimator가 정답 문장들 중 핵심적인 핵심인 내용을 요약하게 된 다. coarse-to-fine modeling framework에서는 이 하위 모듈들을 서로 분리시킴 으로서 좀 더 쿼리에 집중하여 답을 내주는 모델을 만드는데 성공했다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">하위 모듈로 분리시키는 것에 대한 장점은 계산의 측면에서도 존재한다. 기존의 모 델들의 경우, 처음부터 답을 내기까지 모든 과정에서 계속 문서 전체를 데이터로 다루기 때문에 굉장히 많은 연산을 필요로 하게 된다. 하지만 coarse-to-fine 접근 에서는 3번의 하위 모듈을 거쳐가면서 전체 문서의 일부만을 다음 모듈의 입력으로 받게 된다. 이러한 특성 덕분에 결론적으로 기존의 모델들보다 더욱 큰 문서에 대 해서 요약 작업을 수행할 수 있게 된다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">coarse-to-fine 접근법의 가장  큰 장점은 evidence  estimator를 question answering 문제로 다루는 것에 있다. evidence estimator를 question answering 문제로 다루게 되면, 이미 많이 존재하는 QA task를 위한 방대한 데이터의 도움을 받아 QF-MDS 분야의 데이터 부족 현상을 어느 정도 완화할 수 있다. 또한 여러 사전 학습된 인코더들의 도움을 받아 쉽게 성능의 향상을 노릴 수 있다. “Coarse-to-Fine Query Focused Multi-Document Summarization”의 저자들은</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">여러 QA task 중에서도 answer sentence selection과 machine reading comprehension 두 가지 태스크를 목표로 학습한 모델들을 주로 사용하였는데 이 는 쿼리가 길고 복잡한 QF-MDS 분야의 특성 때문에 위 2가지의 태스크가 효과적 이기 때문이다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">이러한 많은 장점에도 불구하고 이번 실험에서 우리는 쿼리가 존재하지 않는 문서 요약을 수행할 예정이기 때문에 위에서 설명한 3가지 모듈 relevance estimator, evidence estimator, centrality estimator 중 relevance estimator와 centrality estimator 만을 사용했다. 왜냐하면 앞서 설명한대로 evidence estimator의 경우, 쿼리에 대한 답을 찾아내는 과정이기 때문에 쿼리가 존재하지 않는 이번 과제에 대 해서는 적용할 수 없다. 또한 relevance estimator의 경우에도 원래의 경우, 쿼리 와 본문간의 유사도를 계산하는 부분을 본문간의 유사도를 계산하는 방식으로 바꿔 주었다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">위에서 설명한 것과 같이 여러 장점이 있는 coarse-to-fine 접근법을 사용하여 한 국어 문서 요약 모델을 만들어 볼 것이다. 앞서 말했듯 EMNLP 2020에서 실린 “Coarse-to-Fine Query Focused Multi-Document Summarization” 논문을 통해 소개된 모델을 기반으로 모델을 만들 것이다. 전체적인 구조는 “Coarse-to-Fine Query Focused Multi-Document Summarization” 논문의 저자들이 깃허브에 올 려놓은 코드를 참고하였고 이 중 한국어 데이터를 처리하기 위해 바꿔줘야 할 부 분, 데이터 전처리 부분에서 토크나이저나 불용어 제거 코드 혹은 모델 부분의 evidence estimator를 제거하는 등 여러 변형을 거쳤다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">학습에 사용한 데이터는 크게 2가지이다. AIHub에서 제공하는 “문서 요약 텍스트”, “요약문 및 레포트 생성데이터“가 그 2 가지이며 이 중 AIHub에서 제공하는 “요약 문 및 레포트 생성데이터“가 가장 다양한 도메인의 자료들을 가지고 있어 가장 우 선적으로 고려한 데이터이다.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 128%;text-align: justify;">학습시킨 모델은 다른 한국어 요약 모델들과 성능 비교 실험을 진행하였다. 성능을 비교 평가한 모델로는 KoBART모델과 KoBertSum 모델이 있다. 각 모델에 대한 성능 평가 방법으로 문서 요약 task에서 흔히 사용하는 ROUGE (Recall-Oriented Understudy for Gisting Evaluation)를 사용한다. ROUGE는 텍스트 자동 요약, 기 계 번역 등 자연어 생성 모델의 성능을 평가하기 위한 지표이며 여러 논문이나 대 회에서도 가장 많이 쓰이는 정량적 평가 기준이다. 이번 연구에서는 ROUGE-1 (unigram-based)의 F1 점수로 평가를 진행할 예정이다.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="397" height="178" alt="image" src="Image_002.jpg"/></span></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part3.htm">&lt; 이전</a><span> | </span><a href="../실험.html">목차</a><span> | </span><a href="part5.htm">다음 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
